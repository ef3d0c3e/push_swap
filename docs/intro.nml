@html.page_title = Push swap in 3500 instructions
@html.css = ./style.css

#+LAYOUT_BEGIN Centered
#*+ Push Swap in 3500 instructions
#+LAYOUT_END

#+TABLE_OF_CONTENT Index

@@style.section = {
	"link_pos": "None",
	"link": ["", "", ""]
}

@tex.main.fontsize = 9
@tex.main.preamble = \usepackage{xcolor, tikz, pgfplots} \\
\usepgfplotslibrary{patchplots} \\
\definecolor{__color1}{HTML}{d5d5d5} \\
\everymath{\color{__color1}\displaystyle}
@tex.main.block_prepend = \color{__color1}

@<main
function gen_values(id, length, stack)
	local colors = { "#2D2D2D", "#1E1E1E" }
	local graph = ""

	-- Values
	for i = 2, length do
		if i <= #stack then
			graph = graph
				.. string.format([[<TR><TD PORT="%d.%d" BGCOLOR="%s" HEIGHT="25" WIDTH="28">%s</TD></TR>]], id, i - 1, colors[1 + i % 2], stack[i])
		else
			graph = graph
				.. string.format([[<TR><TD PORT="%d.%d" HEIGHT="25" BORDER="0" WIDTH="28">&nbsp;</TD></TR>]], id, i - 1)
		end
	end

	return graph
end

function gen_stack(id, length, stack)
	local graph = string.format([[ stack_%d [label=< ]], id)

	-- Stack label
	graph = graph
		.. [[ <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4"> ]]
		.. string.format([[ <TR><TD PORT="title.%d" HEIGHT="25" BORDER="0"><FONT POINT-SIZE="14">%s</FONT></TD></TR> ]], id, stack[1])

	 -- Values
	graph = graph .. gen_values(id, length, stack)

	graph = graph
		.. [[ </TABLE> >] ]]
	return graph
end

function gen_stacks(stacks)
	local graph = [[
		digraph ComputerStack {
			bgcolor=transparent
			node [shape=none, fontcolor=white] ]]

	-- Find longest stack
	local longest = 0
	for k, stack in pairs(stacks) do
		if longest < #stack then
			longest = #stack
		end
	end
	
	local graph_rank = [[{rank=same;]]
	for k, stack in pairs(stacks) do
		graph = graph .. gen_stack(k, longest, stack)


		graph_rank = graph_rank
			.. string.format(" stack_%s", k)
	end

	graph = graph
		.. graph_rank .. "}}"
	return graph
end

function g_stack(stacks)
	nml.graphviz.push("dot", "100%", gen_stacks(stacks))
end

function g_stacks(label, first, second)
	local graph = [[
		digraph ComputerStacks {
			bgcolor=transparent
			node [shape=none, fontcolor=white]
			]]

	-- Find longest stack
	local longest = 0
	for k, stack in pairs(first) do
		if longest < #stack then
			longest = #stack
		end
	end
	for k, stack in pairs(second) do
		if longest < #stack then
			longest = #stack
		end
	end

	local id = 1;
	local rank = [[{rank=same;]]

	-- Left cluster
	graph = graph .. [[ subgraph cluster_left { label="" ]]
	for k, stack in pairs(first) do
		graph = graph .. gen_stack(id, longest, stack)
		rank = rank
			.. string.format(" stack_%s", id)
		id = id + 1
	end
	graph = graph .. [[ } ]]

	local first_right = id

	-- Right cluster
	graph = graph .. [[ subgraph cluster_right { label="" ]]
	for k, stack in pairs(second) do
		graph = graph .. gen_stack(id, longest, stack)
		rank = rank
			.. string.format(" stack_%s", id)
		id = id + 1
	end
	graph = graph .. [[ } ]]

	graph = graph
		.. string.format([[ stack_%d -> stack_%d [color=gray, label="%s", fontcolor=white, penwidth=2, ltail=cluster_left_inner, lhead=cluster_right_inner, labelloc=b]; ]], first_right - 1, first_right, label)

		.. rank .. "}"
		.. "}"
	
	nml.graphviz.push("dot", "100%", graph)
end
>@

# Introduction

*push_swap* is a sorting problem, using a state machine. The state machine requires two 'stacks' to operate and accepts a limited sets of instructions.
The goal of the program is to sort the initial stacks using the fewest number of instructions.
This article is about the optimizations beyond the sorting algorithm.

## The stacks

The original problem mentions the use of two stacks. While they can be represented as stacks, the instructions lets us manipulate them as if they were 'circular'.
In fact the rotate and reverse rotate operation lets us access the bottom of the stack easily.
You find that to push a value to B's bottom translates to `pb rb`.
Which in traditional stack problems would require `O(n)` operations.

If you decide to implement the stacks as contiguous arrays, you'll find that
some operations become very expensive. For instance, every rotate operation
will require you to ``C, memmove(&stack[1], &stack[0], size-1)`` your stack,
in order to move all elements 1 up to make space for the bottom element.

With this information in mind, there are quite a number of data structures that would work for this problem. One could use a circular-doubly-linked-list, they would most certainly work, but be extra painful to deal with later. I found that a double-ended-queue (deque for short) would be more suited for this task. Since adding/removing at their fronts/backs can be implemented very efficiently.
There's a slight twist to this problem, as we already know the maximum size required for our 'stacks'.

Therefore, I've implemented my deque using a constant buffer of size $3 \times N$, where $N$ is the input size. The actual usable buffer is the $ [N,\, 2\times N]$ window. This window has free space it can move inside of. A rotate moves the window 1 down, while a reverse rotate moves it 1 up. When the window has no more space to move into, it is ``C, memcpy``ed to it's original position.

As the buffer has size $3 \times N$, the expensive ``C, memcpy`` happens once every $N$ rotates or reverse-rotates. Which amortizes it's cost, rendering the add/remove to front/back operations `O(1)`.

## Instruction set

Push_swap accepts a total of 11 differnt instructions. Of those 3 are aliases that perform 2 instructions, leaving us with a total of 8 different instructions to work with.

Here are the instructions for our state machine:

#+LAYOUT_BEGIN Split
#+LAYOUT_BEGIN Centered
**pa**
#+LAYOUT_END
Takes the top element of A and push it to B:
%< g_stacks("pa", { {"A", 1, 2, 3}, {"B", "", "", ""} }, { {"A", 2, 3, ""}, {"B", 1, "", ""} })>%

#+LAYOUT_NEXT

#+LAYOUT_BEGIN Centered
**pb**

Takes the top element of B and push it to A:
#+LAYOUT_END
%< g_stacks("pb", { {"A", "2", "", "" }, {"B", 1, 3, ""} }, { {"A", 1, 2, ""}, {"B", 3, "", ""} })>%
#+LAYOUT_END

#+LAYOUT_BEGIN Split
#+LAYOUT_BEGIN Centered
**sa**

Swap A's top two elements:
#+LAYOUT_END
%< g_stacks("sa", { {" "}, {"A", 1, 2, 3} }, { {"A", 2, 1, 3}, {" "}, })>%

#+LAYOUT_NEXT

#+LAYOUT_BEGIN Centered
**sb**

Swap B's top two elements:
#+LAYOUT_END
%< g_stacks("sb", { {" "}, {"B", 1, 3, ""} }, { {"B", 3, 1, ""}, {" "}, })>%
#+LAYOUT_END

#+LAYOUT_BEGIN Split
#+LAYOUT_BEGIN Centered
**ss**

Performs **sa** and **sb**:
#+LAYOUT_END
%< g_stacks("ss", { {"A", "2", "4", "", ""}, {"B", 1, 3, "", ""} }, { {"A", 4, "2", "", ""}, {"B", 3, 1, "", ""} })>%

#+LAYOUT_NEXT

#+LAYOUT_BEGIN Centered
**ra**

Rotates A topwise:
#+LAYOUT_END
%< g_stacks("ra", { {" "}, {"A", "1", "2", "3" } }, { {"A", "2", "3", "1"}, {" "}, })>%
#+LAYOUT_END

#+LAYOUT_BEGIN Split
#+LAYOUT_BEGIN Centered
**rb**

Rotates B topwise:
#+LAYOUT_END
%< g_stacks("rb", { {" "}, {"B", "2", "1", "" } }, { {"B", "1", "2", ""}, {" "}, })>%

#+LAYOUT_NEXT

#+LAYOUT_BEGIN Centered
**rr**

Performs **ra** and **rb**:
#+LAYOUT_END
%< g_stacks("rr", { {"A", "2", "4", "5", "", ""}, {"B", 1, 3, "", "", ""} }, { {"A", 4, "5", 2, "", ""}, {"B", 3, 1, "", "", ""} })>%
#+LAYOUT_END

#+LAYOUT_BEGIN Split
#+LAYOUT_BEGIN Centered
**rra**

Rotates A bottomwise:
#+LAYOUT_END
%< g_stacks("rra", { {" "}, {"A", "2", "1", "3" } }, { {"A", "3", "2", "1"}, {" "} })>%

#+LAYOUT_NEXT

#+LAYOUT_BEGIN Centered
**rrb**

Rotates B bottomwise:
#+LAYOUT_END
%< g_stacks("rrb", { {" "}, {"B", "1", "3", "2"} }, { {"B", 2, 1, 3}, {" "} })>%
#+LAYOUT_END

#+LAYOUT_BEGIN Split
#+LAYOUT_BEGIN Centered
**rrr**

Performs **rra** and **rrb**:
#+LAYOUT_END
%< g_stacks("rrr", { {"A", "2", "4", "5", "", ""}, {"B", 1, 3, "", "", ""} }, { {"A", 5, "2", 4, "", ""}, {"B", 3, 1, "", "", ""} })>%

#+LAYOUT_NEXT

#+LAYOUT_END

## Simulation

In order to simulate outgoing instructions (when sorting) and incoming instructions (when running the checker), I encoded the instructions in a simple format:
#+LAYOUT_BEGIN Centered
``C, |3bits operator selector|2bits stack selector|``
#+LAYOUT_END

For the stack selector:
 * ``C, 01`` means stack `A`
 * ``C, 10`` means stack `B`
 * ``C, 11`` means both stacks

For the operator selector:
 * ``C, 001`` means swap
 * ``C, 010`` means push
 * ``C, 011`` means rotate
 * ``C, 100`` means reverse-rotate

Therefore, operation `pb` is encoded in the following way: ``C, (0b101 << 2) | 0b10``, ``C, 0b101`` represents the push operator, and ``C, 0b10`` represents stack `B`.

The main benefit of this encoding scheme, is to make it easier to write the decoder:
```C, Instruction decoding code
void	stack_op(
		struct s_stack *sa,
		struct s_stack *sb,
		enum e_stack_op op)
{
	struct s_stack *const	ss[2] = {sa, sb};
	const enum e_stack_op	operand = op & __STACK_OPERAND;
	const enum e_stack_op	operator = op & __STACK_OPERATOR;
	size_t					i;

	i = 0;
	while (i < 2)
	{
		if (!(operand & (1 << i)) && ++i)
			continue ;
		else if (operator == __STACK_OP_SWAP && ss[i]->size >= 2)
			swap_impl(ss[i]);
		else if (operator == __STACK_OP_ROTATE && ss[i]->size >= 2)
			rot_impl(ss[i]);
		else if (operator == __STACK_OP_REV_ROTATE && ss[i]->size >= 2)
			rrot_impl(ss[i]);
		else if (operator == __STACK_OP_PUSH && ss[!i]->size >= 1)
			push_impl(ss[!i], ss[i]);
		++i;
	}
}```

# Algorithm

The basis of the algorithm is a [3 multi-quicksort](https://en.wikipedia.org/wiki/Quicksort#Multi-pivot_quicksort).
I'm not the first to use this algorithm for push_swap, you should check
out [this article](https://automatic-saltopus-34b.notion.site/push_swap-c15e62229b9541d78fadec4d6aae8b50)
for details about implementation.

The algorithm takes a block (all the element on A for instance) and split it into 3 smaller blocks according to 2 pivots `(p1, p2)`:
 * Block `min`: Values smaller than `p1`
 * Block `max`: Values between `p1` and `p2`
 * Block `mid`: Values greater than `p2`

Block `max` is moved from A's top to A's bot using `ra`. `mid` is moved over to B's top with `pb`, and `min` is moved to B's bot with `pb rb`.
This operation is repeated until each individual block is small enough (``C, size <= 3``) to be sorted in-place.


## Small sorting

I handle base case sorting for all blocks with ``C, size <= 3``. I have manually built tables to sort from any block to A's top.

For ``C, size == 3``, that makes $3! = 4$ cases, for each possible destination (top A, bot B, etc..).
So in total 24 cases for size 3. Then 8 for size 2, and 1 for size 1.

#+LAYOUT_BEGIN[title=This is the code that dispatch sorting instructions\, according to every possible scenario (only for A's top and B's top)] Spoiler
```C, Sample sorting table for size == 3
	if (blk->dest == BLK_A_TOP)
		((void)(
		   (u > v && v > w && (op(s, STACK_OP_SA), op(s, STACK_OP_RA), op(s, STACK_OP_SA), op(s, STACK_OP_RRA), op(s, STACK_OP_SA), 1))
		|| (u > w && w > v && (op(s, STACK_OP_SA), op(s, STACK_OP_RA), op(s, STACK_OP_SA), op(s, STACK_OP_RRA), 1))
		|| (v > u && u > w && (op(s, STACK_OP_RA), op(s, STACK_OP_SA), op(s, STACK_OP_RRA), op(s, STACK_OP_SA), 1))
		|| (v > w && w > u && (op(s, STACK_OP_RA), op(s, STACK_OP_SA), op(s, STACK_OP_RRA), 1))
		|| (w > u && u > v && (op(s, STACK_OP_SA), 1))
		|| (w > v && v > u && (1))));
	else if (blk->dest == BLK_B_TOP)
		((void)(
		   (u > v && v > w && (op(s, STACK_OP_PA), op(s, STACK_OP_PA), op(s, STACK_OP_PA), 1))
		|| (u > w && w > v && (op(s, STACK_OP_PA), op(s, STACK_OP_SB), op(s, STACK_OP_PA), op(s, STACK_OP_PA), 1))
		|| (v > u && u > w && (op(s, STACK_OP_SB), op(s, STACK_OP_PA), op(s, STACK_OP_PA), op(s, STACK_OP_PA), 1))
		|| (v > w && w > u && (op(s, STACK_OP_SB), op(s, STACK_OP_PA), op(s, STACK_OP_SB), op(s, STACK_OP_PA), op(s, STACK_OP_PA), 1))
		|| (w > u && u > v && (op(s, STACK_OP_PA), op(s, STACK_OP_SB), op(s, STACK_OP_PA), op(s, STACK_OP_SA), op(s, STACK_OP_PA), 1))
		|| (w > v && v > u && (op(s, STACK_OP_SB), op(s, STACK_OP_PA), op(s, STACK_OP_SB), op(s, STACK_OP_PA), op(s, STACK_OP_SA), op(s, STACK_OP_PA), 1))
	));```
#+LAYOUT_END

Another possible way to handle the 3-sort is to use the 2-sort function (which is way shorter). Then handle the special cases where the 2-sort function would not be enough.
However there would be cases where this would generate more instructions, so I opted for the table method. Needless to say, I had to double-check, then triple-check that the values inside the table are correct.

# Optimizations

I will discuss all optimizations I have used in this section.

##{opti_state} Instructions

Instructions are by far the simplest to optimize.

The following is a general optimization technique that works on almost all state-machine problems.
Essentially it may happen that a substring of instructions produces the same output as another (smaller) substring of instructions.
For instance:
 * `ra rb` produces the same side-effect as `rr`.
 * `ra rra` produces the same side-effect as `nop`.
By finding and replacing those substrings, we can lower the instruction count.
However, it's a bit more complicated than that.


Find all instructions substring that can be reduced.

Essentially that would be implemented using a large table, a function would iterate over the instructions and check if a table's substring matches currently.
The downside of this method is that it requires building a large table with all substrings that the function should replace. But once you have the table, most is already done.

However, that doesn't solve the issue entirely.
Consider the following:

Your table contains these mappings: `ra rb → rr` and `rb ra → rr`.
If the program contains the following substring: `ra ra rb rb`,
which can be reduced to `rr rr`, it will only be reduced to `ra rr rb`,
because the table has not enough information. If you go with this method,
be sure to properly populate your table for the best results.
In fact there are $^6P_3 = 20$ combinations for 3 `ra`'s and 3 `rb`'s.
Those could be generated and hard coded into the table.
But I'd rather have a general method that doesn't require
a lot of preliminary work.


### Side-effects

Each instruction will produce it's own side effects. The side effects depends on the instruction, but also on the state of the stacks.
It is important to understand side-effects as they are useful for optimization.

Sometime it may be safe to reorder instructions, as their side effect can be contained:
Suppose that the following program is valid:
#+LAYOUT_BEGIN Centered
``Plain Text, sb ra sa``
#+LAYOUT_END

Because `sb` is the only instruction in the program that acts on B. It is safe to reorder it's execution within the program.
Therefore the program can be simplified to the following:
#+LAYOUT_BEGIN Centered
``Plain Text, ra ss``
#+LAYOUT_END

### Optimizing out unwanted side-effects

In order to reduce the number of instructions after sorting, I use a recursive algorithm that will test random instructions.
Yes, that's right! Using completely random instructions, I'm able to bring the total number of instructions down.

Here's how the algorithm works:
```C, Instruction optimization algorithm
def optimize(states, index, present_state, current_score, best_score, best_future):
	/* Fetch next instruction to 'simulate' */
	for ins in all_instructions:
		/* Simulate the effect of the instruction */
		simulated = simulate(present_state, ins)

		/* Find the last state in `states` that corresponds (i.e same stacks) to `simulated` */
		future = find_future_state(states, index, simulated)
		current_score += index - future.index

		/* Recursive call to simulate another instruction in the current simulation branch
		 * Possible optimization: Evaluate if recursion is worth it. For instance, if current_score
		 * is still 0 after the third recursion, it might be time to stop. */
		optimize(states, index + 1, future, current_score, best_score, best_future)

		/* Update maximum */
		if current_score > best_score:
			best_future = future
			best_score = current_score```

This algorithm works because we have already sorted the input. So we can check if executing a random instruction is going to skip into a future state of the sorting process.

Consider the following sorting program generated by the quicksort algorithm:
	* `index = 0`
	* A: ``C, 0 2 1``
	* B: (empty)
	* F: ``Plain Text, ra ra sa`` (this will sort A)
After executing the first 2 instructions, the program ends up in this state:
	* `index = 2`
	* A: ``C, 1 0 2``
	* B: (empty)
	* F: ``Plain Text, sa``

However, the `optimize` algorithm would, at one point, have tried the `rra` instruction for `index = 0`.
When it simulates the effect of `rra`, the algorithm would end up with the same stacks as that of `index = 2`.
Therefore the algorithm keeps `rra` and skips directly to the final `sa`. Thus reducing the sorting program to F = ``Plain Text, rra sa``.

The key is to also try to do nothing: `nop`. And check if by doing nothing we can advance to a future state of the sorting program.
This also has the benefit of removing 'useless' instructions. For instance, rotating a stack with < 2 elements.

Of course this algorithm is guaranteed to find the best optimizations, however we can't let it recurse indefinitely. Thus, i've set the maximum recursion depth to 2, which seems to yield good enough results while not impeding performances too much.

#+LAYOUT_BEGIN Split


#+LAYOUT_NEXT
#+LAYOUT_END

## Optimizing quicksort

Quicksort is already as fast as a sorting algorithm can be: `O(n log n)`. At least, it should be according to theory.
However we're looking to get below 4500 instructions to sort 500 elements. It should be noted that there are quite a few different way to implement quicksort.

### Better pivots

The 3 multi-quicksort algorithm I'm using requires 2 pivot to split in 3 separate blocks. I originally used quartiles (Q1, Q3) as the two pivots, as they should split in 3 blocks of similar size. But could we choose better values than quartiles?

But before we get to constructing them, we need a way to evaluate them. Since we want to minimize the total number of instructions, we can define the cost of a pivot pair as the following:

```C, Pivots cost function
def pivots_cost(state, block, pivots):
	/* Store operation count */
	current_op_count = state.op_count

	/* Split in 3 using the provided pivots */
	split = split(state, block, pivots)

	/* Regular sorting logic, derived from the 3-multi-quicksort */
	sort(split.max)
	sort(split.mid)
	sort(split.min)

	/* Return score */
	return state.op_count - current_op_count```

Here's the result of the cost function for testing out pivots to sort 500 integers:

![heatmap](./heatmap.png)[caption=Pivots heatmap] Cost function values for pivots, tested with 500 random integers. Only the first pivot choice is represented. Other pivots use quartiles (Q1, Q3).

From this we can clearly see that there seems to be a sweet spot around (0.2, 0.6). But using this method to determine the best pivots is unreasonably slow!
Also these are the result for the initial unsorted array. As the data gets partially sorted, optimal pivots may vary a lot.
We could generate a table and make lookup to it in order to get good pivots, but building such a table is a whole different project.
Instead I'm going to introduce a heuristic method that finds 'good enough' pivots.

### Simulated Annealing

When trying to find minimum (or maximum) the [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) technique is quite popular for it's effectiveness.
Sadly, it may not work in this case. The cost function may not be differentiable, let alone continuous.
Also it easily gets stuck on local minima instead of finding the absolute minimum.

A similar numerical method to find minima exists and is more reliable at 'not getting stuck on local minima'.
Introducing [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing).
The main advantage of this method is that no matter what the `cost` function looks like,
this is guaranded to find good pivots (given the right parameters...).
But this method is very expesive as it's going to call to our `pivots_cost` function, which may in turn call back to the pivot searching algorithm.

You get the idea, this method is guaranted to find good pivots -- at the cost of being very expensive. However we don't really care about the time it takes to sort, we'd rather minimize the instruction count required for sorting.

### Fine-tuning

In order to pass this assignment, the program must sort 500 elements in less than a minute and use less than 4500 instructions doing so.
I've manually tested values until I could find set and forget values, that make sure the program always finishes fast enough with good-enough results.

 * ``C, temperature_initial``: ``C, 1.0f``
 * ``C, temperature_min``: ``C, .1f``
 * ``C, temperature_cooling``: ``C, .95f``
 Fast cooldown rate
 * ``C, factor_step``: ``C, 0.15f``
 Try values over a large neighboorhood
 * ``C, max_tries``: ``C, 3``
 Very few tries per temperature cycle
 * ``C, max_anneal``: ``C, 2``
 Max annealing recursion depth. Any other value larger than 2 will make it really slow to sort more than 100 elements.
 * ``C, max_fast_anneal``: ``C, 0``

### Edge-cases

Quicksort is already a really good algorithm, being the default sorting algorithm in C, C++, Rust. However there's an issue with quicksort.
When the input is almost sorted (e.g everything sorted but one element) quicksort turns out to be very slow -- sometimes slower than bubble sort.

This is the reason why most sorting algorithm relying on quicksort, use an alternative algorithm (e.g heapsort) when detecting a worst-case.
I recommend reading [Pattern-Defeating Quicksort](https://github.com/orlp/pdqsort) which is quicksort variant that tries to efficiently detect these edge-cases and resort to other sorting algorithm.

By lack of time, I decided not to implement such a strategy for push_swap.

# Utility

I discuss the utility functions I've used for `push_swap`.

## Moving values

Push_swap required me to move values from one place to another. I found that writing a ``C,blk_move`` function that does it is very handy.

Here's the table that tells us what moves are required to move values (row: *move from*, columns: *move to*):
|:talign=center: |  ``TOP A``  |  ``BOT A``  | ``TOP B``  |  ``BOT B``  |
| ``TOP A``      |             |**    ra   **|**  pb    **|** pb   rb **|
| ``BOT A``      |**  rra    **|**         **|**rra  pb **|**rra pb rb**|
| ``TOP B``      |** pa      **|** pa   ra **|**        **|**   rb    **|
| ``BOT B``      |** rrb  pa **|**rrb pa ra**|** rrb    **|**         **|

Using this table, I implement the following move function that moves from any location to any other location:

```C, Move function
void	blk_move(t_state *s, enum e_blk_dest from, enum e_blk_dest to)
{
	const uint8_t	id = (from << 2) | to;

	/* Check if move is legal */
	if (((from & __BLK_SEL) == __BLK_A && !s->sa.size)
		|| ((from & __BLK_SEL) == __BLK_B && !s->sb.size))
		return ;
	/* Move table */
	(void)((!(id % 5))
		|| (id == 1 && (op(s, STACK_OP_RA), 1))
		|| (id == 2 && (op(s, STACK_OP_PB), 1))
		|| (id == 3 && (op(s, STACK_OP_PB), op(s, STACK_OP_RB), 1))
		|| (id == 4 && (op(s, STACK_OP_RRA), 1))
		|| (id == 6 && (op(s, STACK_OP_RRA), op(s, STACK_OP_PB), 1))
		|| (id == 7 && (op(s, STACK_OP_RRA), op(s, STACK_OP_PB),
			op(s, STACK_OP_RB), 1))
		|| (id == 8 && (op(s, STACK_OP_PA), 1))
		|| (id == 9 && (op(s, STACK_OP_PA), op(s, STACK_OP_RA), 1))
		|| (id == 11 && (op(s, STACK_OP_RB), 1))
		|| (id == 12 && (op(s, STACK_OP_RRB), op(s, STACK_OP_PA), 1))
		|| (id == 13 && (op(s, STACK_OP_RRB), op(s, STACK_OP_PA),
			op(s, STACK_OP_RA), 1))
		|| (id == 14 && (op(s, STACK_OP_RRB), 1)));
}
```

#* References

 * [Push swap quick sort implementation](https://automatic-saltopus-34b.notion.site/push_swap-c15e62229b9541d78fadec4d6aae8b50)
 * [Simulated Annealing](https://en.wikipedia.org/wiki/Simulated_annealing)
 * [Pattern-Defeating Quicksort](https://github.com/orlp/pdqsort)
